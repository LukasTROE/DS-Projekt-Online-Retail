# üöÄ Startup Growth & Funding Trends Analysis

## üìä Projekt√ºbersicht

Dieses Data-Science-Projekt analysiert Wachstums- und Finanzierungsdaten von 500 Startups, um **profitable Investments f√ºr Investoren zu identifizieren**. Durch Machine Learning und explorative Datenanalyse werden Erfolgsmuster erkannt und ein **Empfehlungsmodell** entwickelt, das datenbasierte Investitionsentscheidungen unterst√ºtzt und psychologische Verzerrungen (Biases) reduziert.

## üë• Gruppenmitglieder

- Engel, Silas
- Nolepa, Mark
- Schneider, Tom
- Tr√∂lenberg, Lukas

## üéØ Gesch√§ftsziel

**Hauptziel:** Gro√üe Mengen an Startups ressourceneffizient bewerten und profitable Investments identifizieren.

**Kernfragen:**
- Welche Kennzahlen beeinflussen die Profitabilit√§t f√ºr Investoren?
- Wie gut kann ein datenbasiertes Modell die Profitabilit√§t von Startups vorhersagen?
- In welche Startups mit hohem Wachstumspotenzial sollte investiert werden?

**Nutzen:**
- Objektive Bewertung statt Bauchgef√ºhl
- Risikominimierung durch datenbasierte Analyse
- Effiziente Filterung vielversprechender Startups
- Reduktion von Confirmation Bias, Halo-Effekt und Recency Bias

## üìÅ Projektstruktur

```
DS-Projekt-Startup-Growth-final/
‚îÇ
‚îú‚îÄ‚îÄ Startup.ipynb          # Hauptanalyse-Notebook
‚îú‚îÄ‚îÄ startup_data.csv       # Datensatz (500 Startups)
‚îú‚îÄ‚îÄ requirements.txt       # Python-Abh√§ngigkeiten
‚îú‚îÄ‚îÄ Dockerfile             # Container-Setup
‚îî‚îÄ‚îÄ README.md              # Projektdokumentation
```

## üìà Datensatz

**Quelle:** [Kaggle - Startup Growth and Funding Trends](https://www.kaggle.com/datasets/samayashar/startup-growth-and-funding-trends)

**Beschreibung:**  
Umfassende Daten √ºber Startups, ihre Finanzierungsrunden, Wachstumsmetriken und Unternehmensentwicklung. Der Datensatz enth√§lt Informationen zu:

- **Unternehmensdetails:** Name, Gr√ºndungsjahr, Branche, Standort
- **Finanzierung:** Funding-Runden, Investitionsvolumen, Investoren
- **Wachstum:** Mitarbeiterentwicklung, Umsatzwachstum, Bewertung
- **Performance:** Erfolgsmetriken, Exit-Status, Entwicklungsstadium

**Zentrale Variablen (500 Startups):**

| Variable | Typ | Beschreibung |
|----------|-----|--------------|
| Startup Name | Text | Name des Startups |
| Industry | Kategorial | Branche (EdTech, FinTech, HealthTech, E-Commerce, CleanTech) |
| Region | Kategorial | Region (North America, Europe, Asia) |
| Funding Amount (M USD) | Numerisch | Investitionssumme in Mio. USD |
| Valuation (M USD) | Numerisch | Unternehmensbewertung in Mio. USD |
| Revenue (M USD) | Numerisch | Umsatz in Mio. USD |
| Number of Employees | Numerisch | Mitarbeiteranzahl |
| Years in Operation | Numerisch | Betriebsjahre |
| Market Share (%) | Numerisch | Marktanteil in Prozent |
| Customer Growth Rate (%) | Numerisch | Kundenwachstumsrate |
| Profitable | Bin√§r | Profitabilit√§t (1 = profitabel, 0 = unprofitabel) |

## üîç Analyseschwerpunkte

### Teil 1: Business Understanding & Datenexploration
- **Business Kontext:** Zielsetzung, Gesch√§ftsfragen, Warum Data Science?
- **Explorative Datenanalyse (EDA):** 
  - Vergleich profitabler vs. unprofitabler Startups (Umsatz, Bewertung, Mitarbeiter)
  - Branchenverteilung und regionale Analyse
  - Korrelationsanalyse (Pearson, Spearman)
  - Identifikation von Verzerrungen (Bias-Analyse)
  - Kapitaleffizienz-Analyse (Revenue per Invested Dollar)
  - Marktanteil und Erfolgsfaktoren

### Teil 2: Datenaufbereitung
- **Fehlende Werte:** Identifikation und Behandlung
- **Ausrei√üer-Behandlung:** IQR-Methode, Clipping-Strategien
- **Feature Engineering:**
  - Neue Metriken: Kapitaleffizienz, Branchenmarktanteil
  - Bin√§re Features: High Valuation, High Revenue Growth
  - Interaktionseffekte zwischen Features

### Teil 3: Modellierung & Evaluation
- **Modellauswahl:** Logistische Regression f√ºr bin√§re Klassifikation (Profitabel/Unprofitabel)
- **Train-Test-Split:** 80/20-Aufteilung
- **Feature Selection:** Relevante Pr√§diktoren identifizieren
- **Evaluation:**
  - Confusion Matrix (TP, FP, TN, FN)
  - Accuracy, Precision, Recall, F1-Score
  - Fokus auf Risikominimierung (False Positives reduzieren)
- **Hyperparameter-Tuning:** Threshold-Optimierung

### Teil 4: Erkenntnisse & Handlungsempfehlungen
- **Konkrete Investitionsempfehlungen**
- **Modellgrenzen und Limitationen**
- **Kritische Fragen:** Datenqualit√§t, Repr√§sentativit√§t, Kausalit√§t
- **N√§chste Schritte:** Erweiterungsm√∂glichkeiten (gr√∂√üere Datens√§tze, Ensemble-Methoden, Survival Analysis)

## üõ†Ô∏è Verwendete Technologien

### Core Libraries
- **Python 3.13**
- **Jupyter Notebook / VS Code**

### Data Processing & Analysis
- **Pandas** - Datenmanipulation und -analyse
- **NumPy** - Numerische Berechnungen
- **SciPy** - Statistische Tests und wissenschaftliche Berechnungen

### Visualization
- **Matplotlib** - Basis-Visualisierungen
- **Seaborn** - Statistische Plots und Heatmaps
- **Plotly Express** - Interaktive Visualisierungen (Bubble Charts, 3D-Plots)

### Machine Learning
- **Scikit-learn** - Logistische Regression, Train-Test-Split, Metriken
- **IPython.display** - Notebook-Darstellung

## üöÄ Installation & Ausf√ºhrung

### Voraussetzungen
- **Python 3.8+** (empfohlen: 3.13)
- **pip** (Python Package Manager)
- **Jupyter Notebook** oder **VS Code mit Python Extension**

### Setup

#### Option 1: Automatische Installation (empfohlen)
Das Notebook installiert automatisch alle ben√∂tigten Module beim ersten Ausf√ºhren der Installationszelle.

1. **Repository klonen oder herunterladen**
```bash
git clone <repository-url>
cd DS-Projekt-Startup-Growth-final
```

2. **Notebook √∂ffnen**
```bash
jupyter notebook StartUp.ipynb
# oder mit VS Code
code StartUp.ipynb
```

3. **Erste Zellen ausf√ºhren** - Die Installation l√§uft automatisch

#### Option 2: Manuelle Installation
```bash
pip install -r requirements.txt
```

Oder einzeln:
```bash
pip install pandas numpy matplotlib seaborn plotly scikit-learn scipy ipython
```

### Docker Setup (Optional)
```bash
docker build -t startup-analysis .
docker run -p 8888:8888 startup-analysis
```

## üìä Notebook-Struktur (StartUp.ipynb)

### Teil 0: Setup
- Automatische Modulinstallation
- Import aller ben√∂tigten Libraries
- Laden des Datensatzes (`startup_data.csv`)

### Teil 1: Business Understanding & Datenexploration
1. **Business Kontext**
   - Gesch√§ftsproblem und Zielsetzung
   - Warum Data Science f√ºr Startup-Investments?
   
2. **Explorative Datenanalyse (EDA)**
   - **Graph V1:** Umsatzvergleich profitabel vs. unprofitabel
   - **Graph V2:** Verteilung der Startups nach Industrie
   - **Graph V3:** Regionale Verteilung
   - **Graph V4:** Bewertung vs. Investitionssumme (Bubble Chart)
   - **Graph V5:** 3D-Visualisierung (Marktanteil, Umsatz, Bewertung)
   - **Graph V6:** Kapitaleffizienz-Analyse (Top 30 nach Revenue/Investment)
   - **Korrelationsmatrix:** Pearson & Spearman
   - **Bias-Analyse:** Identifikation systematischer Verzerrungen
   - **Marktanteil-Analyse:** Korrelation mit Erfolgsmetriken

### Teil 2: Datenaufbereitung
1. **Fehlende Werte behandeln**
2. **Ausrei√üer-Erkennung und -Behandlung** (IQR-Methode)
3. **Feature Engineering:**
   - Kapitaleffizienz berechnen
   - Branchenmarktanteil
   - Bin√§re High-Performance-Features

### Teil 3: Modellierung
1. **Modellauswahl:** Logistische Regression
2. **Train-Test-Split** (80/20)
3. **Feature Selection**
4. **Model Training**
5. **Evaluation:**
   - Confusion Matrix
   - Precision, Recall, F1-Score
   - Threshold-Optimierung
6. **Top-Startup-Empfehlungen** (nach Wahrscheinlichkeit sortiert)

### Teil 4: Insights & Next Steps
1. **Konkrete Investitionsempfehlungen**
2. **Modellgrenzen und Limitationen**
3. **Kritische Reflexion:**
   - Datenqualit√§t
   - Repr√§sentativit√§t
   - Kausalit√§t vs. Korrelation
4. **Weiterf√ºhrende Analysem√∂glichkeiten:**
   - Gr√∂√üere Datens√§tze
   - Ensemble-Methoden
   - Survival Analysis
   - Kausalinferenz

## üìà Wichtigste Erkenntnisse

### Datenanalyse-Insights
- **Branchenverteilung:** EdTech und FinTech dominieren den Datensatz
- **Regionale Unterschiede:** North America f√ºhrt bei Investitionsvolumen
- **Korrelationen:** Starker Zusammenhang zwischen Funding Amount und Valuation (r=0.8)
- **Kapitaleffizienz:** Gro√üe Varianz zwischen Branchen und Startups
- **Marktanteil:** Positiver, aber schwacher Zusammenhang mit Profitabilit√§t

### Modell-Performance
- **Accuracy:** ~60%
- **Precision:** Fokus auf Risikominimierung (False Positives reduzieren)
- **Recall:** ~35% (Trade-off zugunsten h√∂herer Precision)
- **Ergebnis:** Modell schl√§gt Zufallsrate (50%) und reduziert Investitionsrisiko

### Empfehlungen
1. **Nicht blind investieren** - Top 10-20 Startups genauer pr√ºfen
2. **Portfolio-Diversifikation** - In mehrere vorgeschlagene Startups investieren
3. **Qualitative Faktoren beachten** - Team, Vision, Produkt-Market-Fit
4. **Datenbasiert entscheiden** - Bauchgef√ºhl durch objektive Metriken erg√§nzen

## üöß Limitationen

- **Kleiner Datensatz:** Nur 500 Startups
- **Survivorship Bias:** Gescheiterte Startups m√∂glicherweise unterrepr√§sentiert
- **Fehlende Features:** Gr√ºnderteam-Erfahrung, Netzwerkeffekte, Marktdynamiken
- **Zeitliche Effekte:** Keine Normalisierung nach Unternehmensalter/Gr√ºndungsjahr
- **Kausalit√§t unklar:** Korrelation ‚â† Kausalit√§t

## üîÆ Zuk√ºnftige Erweiterungen

- Gr√∂√üerer Datensatz (5.000-10.000 Startups)
- Ensemble-Methoden (Random Forest, Gradient Boosting)
- Survival Analysis (Zeit bis Profitabilit√§t)
- NLP-Analyse von Pitch Decks und Business Plans
- Einbindung makro√∂konomischer Variablen
- Real-Time-Daten und API-Integration

## üìù Lizenz & Datenquelle

**Datensatz:** [Startup Growth & Funding Trends - Kaggle](https://www.kaggle.com/datasets/samayashar/startup-growth-and-funding-trends)

Der Datensatz wird gem√§√ü der Kaggle-Nutzungsbedingungen verwendet. Dieses Projekt dient ausschlie√ülich akademischen und Lernzwecken.

---

**Projektarbeit im Rahmen des Kurses "Introduction to Data Science"**  

¬© 2025 | Tom Scheider, Mark Nolepa, Lukas Tr√∂lenberg, Silas Engel
