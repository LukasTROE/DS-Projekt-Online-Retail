{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16e144e9",
   "metadata": {},
   "source": [
    "# Vorhersage profitabler Startups mit Decision Trees\n",
    "\n",
    "Dieses Notebook zeigt, wie auf Basis eines Startup-Datensatzes ein **klassifikationsbasiertes Machine-Learning-Modell** aufgebaut wird, um die Frage zu beantworten:\n",
    "\n",
    "> *„Welche Startups sind mit hoher Wahrscheinlichkeit ein profitables Investment?“*\n",
    "\n",
    "Das Vorgehen orientiert sich an den in der Vorlesung behandelten Data-Science-Prozessmodellen (z. B. **CRISP-DM**) sowie den Inhalten zu\n",
    "\n",
    "- **Datenaufbereitung & Feature Engineering** (Tag 4),\n",
    "- **Einführung in Maschinelles Lernen** (Tag 6),\n",
    "- **Modellbewertung & Metriken** (Tag 8).\n",
    "\n",
    "Im Fokus stehen dabei:\n",
    "1. Feature Engineering\n",
    "2. Implementierung und Begründung eines Modells (Decision Tree)\n",
    "3. Angemessene Metriken zur Evaluierung des Modells\n",
    "4. Diskussion von Overfitting und Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c454d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# Auswertungseinstellungen\n",
    "TOP_K = 10       # Wie viele Topunternehmen sollen angezeigt werden\n",
    "RNG = 42         # Zufallszahl für Reproduzierbarkeit\n",
    "THRESHOLD = 0.6  # Schwelle, ab der ein Startup als profitabel (1) klassifiziert wird"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f58a5",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering und Erstellung des Modelldatenrahmens\n",
    "\n",
    "In diesem Schritt werden die Rohdaten so vorbereitet, dass sie für ein ML-Modell nutzbar werden. Entsprechend der Vorlesung zu **Datenaufbereitung & Feature Engineering** werden:\n",
    "\n",
    "- die **Zielvariable** `Profitable` definiert,\n",
    "- relevante **numerische** und **kategorische** Features ausgewählt,\n",
    "- zusätzliche Kennzahlen über **Feature Engineering** abgeleitet,\n",
    "- Trainings- und Testdaten mit `train_test_split` erstellt.\n",
    "\n",
    "Wichtig ist dabei, **keine Informationen zu verwenden, die erst nach der Investitionsentscheidung bekannt wären**, z. B. Exit-Status oder tatsächliche Profitabilität. Sonst würde das Modell „in die Zukunft schauen“ (Data Leakage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cc048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Daten laden ---\n",
    "df = pd.read_csv(\"startup_data.csv\")\n",
    "y = df[\"Profitable\"].astype(int)\n",
    "\n",
    "df_model = df.copy()\n",
    "\n",
    "# --- Features, die ans Modell übergeben werden sollen ---\n",
    "\n",
    "# numerisch\n",
    "num = [\n",
    "    \"Funding Rounds\", \"Funding Amount (M USD)\", \"Valuation (M USD)\",\n",
    "    \"Revenue (M USD)\", \"Employees\", \"Market Share (%)\", \"Year Founded\"\n",
    "]\n",
    "\n",
    "# kategorisch\n",
    "cat = [\"Industry\", \"Region\"]\n",
    "\n",
    "# Wichtig: Es werden nur Merkmale verwendet, die vor einer Investition bekannt sind.\n",
    "# Exit-Status oder tatsächliche Profitabilität bleiben explizit außen vor.\n",
    "\n",
    "# --- Feature-Engineering-Schritte ---\n",
    "\n",
    "# Verhältnis zwischen Finanzierungsbetrag und Anzahl an Finanzierungsrunden\n",
    "df_model[\"Funding_per_Round\"] = df[\"Funding Amount (M USD)\"] / df[\"Funding Rounds\"].clip(lower=1)\n",
    "\n",
    "# Verhältnis zwischen Umsatz und Mitarbeiterzahl (Produktivität)\n",
    "df_model[\"Rev_per_Emp\"] = df[\"Revenue (M USD)\"] / df[\"Employees\"].clip(lower=1)\n",
    "\n",
    "# Verhältnis zwischen Umsatz und Finanzierungsbetrag (Kapital-Effizienz)\n",
    "df_model[\"Capital_Eff\"] = df[\"Revenue (M USD)\"] / df[\"Funding Amount (M USD)\"]\n",
    "\n",
    "# Verhältnis zwischen Umsatz und Unternehmensbewertung\n",
    "df_model[\"Revenue_to_Valuation\"] = df[\"Revenue (M USD)\"] / df[\"Valuation (M USD)\"].replace(0, np.nan)\n",
    "\n",
    "# Neue Features zur numerischen Feature-Liste hinzufügen\n",
    "num += [\n",
    "    \"Funding_per_Round\",\n",
    "    \"Rev_per_Emp\",\n",
    "    \"Capital_Eff\",\n",
    "    \"Revenue_to_Valuation\",\n",
    "]\n",
    "\n",
    "# Finale Feature-Matrix\n",
    "X = df_model[num + cat].copy()\n",
    "\n",
    "# --- Train/Test-Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    stratify=y,\n",
    "    random_state=RNG\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe6eb9",
   "metadata": {},
   "source": [
    "## 2. Implementierung und Begründung des Modells\n",
    "\n",
    "Für die Klassifikation wird ein **Decision Tree Classifier** verwendet. Diese Wahl ist im Kontext der Vorlesung begründbar durch:\n",
    "\n",
    "- **Interpretierbarkeit:** Entscheidungsbäume lassen sich als Entscheidungsregeln erklären (z. B. „Wenn Market Share > x und Funding Rounds < y, dann …“).\n",
    "- **Umgang mit nichtlinearen Zusammenhängen:** Bäume können Interaktionen zwischen Features abbilden.\n",
    "- **Klares Bias/Varianz-Verhalten:** Bäume sind didaktisch gut geeignet, um Overfitting/Underfitting zu diskutieren (z. B. über `max_depth`).\n",
    "\n",
    "Die Vorverarbeitung wird in einer **Pipeline** gekapselt:\n",
    "- Numerische Daten: Imputation mit Median + Min-Max-Skalierung\n",
    "- Kategorische Daten: Imputation mit häufigstem Wert + One-Hot-Encoding\n",
    "- Anschließend wird der Decision Tree auf die transformierten Features trainiert.\n",
    "\n",
    "Damit folgt das Vorgehen dem in der Vorlesung empfohlenen Prinzip: *„Preprocessing und Modell in einer einheitlichen Pipeline bündeln“*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8bbf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pipeline zur Vorverarbeitung ---\n",
    "\n",
    "# Numerischer Zweig: Imputation + MinMax-Skalierung\n",
    "num_pre = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),     # Fehlende numerische Werte -> Median\n",
    "    (\"scale\", MinMaxScaler(feature_range=(0, 1)))  # Skalierung auf [0,1], reduziert Skalen-Bias\n",
    "])\n",
    "\n",
    "# Kategorialer Zweig: Imputation + One-Hot-Encoding\n",
    "cat_pre = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),  # Fehlende Kategorien -> häufigster Wert\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))    # One-Hot-Encoding, unbekannte Kategorien ignorieren\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", num_pre, num),\n",
    "    (\"cat\", cat_pre, cat)\n",
    "])\n",
    "\n",
    "# --- Decision Tree Modell ---\n",
    "tree = DecisionTreeClassifier(\n",
    "    max_depth=7,          # Begrenzung der Tiefe zur Vermeidung von Overfitting\n",
    "    min_samples_leaf=40,  # Mindestanzahl von Startups pro Blatt\n",
    "    criterion=\"gini\",     # Gini-Index als Reinheitsmaß\n",
    "    random_state=RNG\n",
    ")\n",
    "\n",
    "# Gesamte Pipeline: Preprocessing + Modell\n",
    "pipe = Pipeline([(\"prep\", pre), (\"model\", tree)])\n",
    "\n",
    "# Training\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersage von Wahrscheinlichkeiten (Klasse 1 = profitabel)\n",
    "y_train_proba = pipe.predict_proba(X_train)[:, 1]\n",
    "y_test_proba  = pipe.predict_proba(X_test)[:, 1]\n",
    "y_test_pred   = (y_test_proba >= THRESHOLD).astype(int)\n",
    "\n",
    "y_train_proba[:5], y_test_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd235eec",
   "metadata": {},
   "source": [
    "## 3. Modellbewertung: geeignete Metriken\n",
    "\n",
    "Entsprechend der Vorlesung zu **Modellbewertung (Tag 8)** wird das Modell mit mehreren Metriken beurteilt:\n",
    "\n",
    "- **ROC-AUC**: misst, wie gut das Modell zwischen profitabel/nicht profitabel unterscheidet, unabhängig vom Threshold.\n",
    "- **Accuracy**: Anteil der korrekt klassifizierten Startups.\n",
    "- **Precision (Positiv-Präzision)**: *„Wie viele der als profitabel vorhergesagten Startups waren tatsächlich profitabel?“*  \n",
    "  → wichtig, um **Fehlinvestitionen (False Positives)** zu begrenzen.\n",
    "- **Recall (Sensitivität)**: *„Wie viele der tatsächlich profitablen Startups wurden vom Modell erkannt?“*  \n",
    "  → wichtig, um **verpasste Chancen (False Negatives)** zu reduzieren.\n",
    "- **F1-Score**: harmonisches Mittel aus Precision und Recall, nützlich bei unbalancierten Klassen.\n",
    "- **Confusion Matrix**: detaillierte Übersicht über TP, FP, FN, TN.  \n",
    "  Hier zusätzlich mit **Business-Begriffen** annotiert (gutes Investment, verpasste Chance, schlechtes Investment, erkanntes Minusgeschäft)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b04038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ROC-AUC ---\n",
    "roc_train = roc_auc_score(y_train, y_train_proba)\n",
    "roc_test  = roc_auc_score(y_test,  y_test_proba)\n",
    "\n",
    "print(f\"ROC-AUC Train: {roc_train:.3f}\")\n",
    "print(f\"ROC-AUC Test : {roc_test:.3f}\\n\")\n",
    "\n",
    "\n",
    "# --- Klassifikationsmetriken ---\n",
    "acc  = accuracy_score(y_test, y_test_pred)\n",
    "prec = precision_score(y_test, y_test_pred)\n",
    "rec  = recall_score(y_test, y_test_pred)\n",
    "f1   = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Test-Metriken:\")\n",
    "print(f\"Accuracy : {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall   : {rec:.3f}\")\n",
    "print(f\"F1-Score : {f1:.3f}\\n\")\n",
    "\n",
    "\n",
    "print(\"Classification Report (Test):\\n\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=[\"Nicht profitabel\", \"Profitabel\"]))\n",
    "\n",
    "\n",
    "# --- Confusion-Matrix mit Business-Begriffen ---\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Vorhersage des Modells\")\n",
    "ax.set_ylabel(\"Tatsächlicher Status\")\n",
    "\n",
    "\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels([\"Nicht profitabel (0)\", \"Profitabel (1)\"])\n",
    "ax.set_yticklabels([\"Nicht profitabel (0)\", \"Profitabel (1)\"])\n",
    "\n",
    "ax.set_title(\n",
    "    \"Confusion Matrix – Gutes Investment (TP), \"\n",
    "\n",
    "    \"Verpasste Chance (FN),\\n\"\n",
    "\n",
    "    \"Schlechtes Investment (FP), Erkanntes Minusgeschäft (TN)\"\n",
    ")\n",
    "\n",
    "business_labels = [\n",
    "    [\"Erkanntes Minusgeschäft\\n(TN)\", \"Schlechtes Investment\\n(FP)\"],\n",
    "    [\"Verpasste Chance\\n(FN)\", \"Gutes Investment\\n(TP)\"]\n",
    "]\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = f\"{business_labels[i][j]}\\n{cm[i, j]}\"\n",
    "        ax.text(\n",
    "            j, i,\n",
    "            text,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"black\",\n",
    "            fontsize=8\n",
    "        )\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd8b7ee",
   "metadata": {},
   "source": [
    "## 4. Feature Importance des Decision Trees\n",
    "\n",
    "Um das Modell besser erklären zu können (Stichwort **Explainable AI** aus der Vorlesung), wird die **Feature Importance** des Decision Trees ausgewertet.\n",
    "\n",
    "- Sie zeigt, welche Features besonders stark zur Trennung der Klassen beitragen.\n",
    "- Durch das One-Hot-Encoding der Kategorien entstehen zusätzliche binäre Features (z. B. einzelne Industriezweige).\n",
    "- So lassen sich fachliche Fragen beantworten wie:\n",
    "  - Welche Rolle spielt der **Marktanteil**?\n",
    "  - Wie wichtig sind **Finanzierungsrunden** oder **Kapital-Effizienz**?\n",
    "  - Welche Branchen oder Regionen sind im Modell besonders relevant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zugriff auf das trainierte Baum-Modell und den One-Hot-Encoder\n",
    "best_tree = pipe.named_steps[\"model\"]\n",
    "ohe = pipe.named_steps[\"prep\"].named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "\n",
    "# Feature-Namen: numerische Features + One-Hot-Features\n",
    "feature_names = num + list(ohe.get_feature_names_out(cat))\n",
    "importances = best_tree.feature_importances_\n",
    "\n",
    "imp_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(\"Importance\", ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, max(6, len(imp_df) * 0.25)))\n",
    "plt.barh(imp_df[\"Feature\"], imp_df[\"Importance\"])\n",
    "plt.xlabel(\"Wichtigkeit im Modell\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance – Decision Tree Classifier\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "imp_df.sort_values(\"Importance\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98e4c6c",
   "metadata": {},
   "source": [
    "## 5. Diskussion von Overfitting und Underfitting\n",
    "\n",
    "In der Vorlesung wurde das Spannungsfeld zwischen **Bias** und **Varianz** sowie **Overfitting** und **Underfitting** erläutert.  \n",
    "Anhand dieses Modells lässt sich das wie folgt einordnen:\n",
    "\n",
    "- Ein **zu komplexer Baum** (sehr große `max_depth`, kleine `min_samples_leaf`) würde\n",
    "  - die Trainingsdaten fast perfekt trennen (sehr hohe ROC-AUC/Accuracy im Training),\n",
    "  - aber auf den Testdaten deutlich schlechter abschneiden → **Overfitting (hohe Varianz)**.\n",
    "\n",
    "- Ein **zu einfacher Baum** (sehr kleine `max_depth`) würde\n",
    "  - sowohl auf Trainings- als auch Testdaten eher schlechte Werte liefern,\n",
    "  - weil die Modellkapazität nicht ausreicht, die Zusammenhänge abzubilden → **Underfitting (hoher Bias)**.\n",
    "\n",
    "In diesem Notebook wurde versucht, einen **Kompromiss** zu finden:\n",
    "\n",
    "- `max_depth = 7` begrenzt die Komplexität des Baums.\n",
    "- `min_samples_leaf = 40` sorgt dafür, dass Blätter nicht nur auf sehr wenigen Startups basieren.\n",
    "- Ein Blick auf `ROC-AUC Train` vs. `ROC-AUC Test` zeigt, ob das Modell stärker zum Overfitting neigt:\n",
    "  - Liegt der Trainingswert deutlich über dem Testwert, ist dies ein Indiz für Overfitting.\n",
    "  - Sind beide Werte ähnlich, spricht das für ein **robusteres Modell**.\n",
    "\n",
    "Damit ist die Diskussion von Over-/Underfitting sauber an den im Notebook berechneten Metriken verankert und knüpft direkt an die theoretischen Inhalte der Vorlesung an."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec3c37",
   "metadata": {},
   "source": [
    "## 6. Fazit\n",
    "\n",
    "Dieses Notebook demonstriert einen kompletten, aber kompakten ML-Workflow für die Frage, welche Startups ein **attraktives Investment** darstellen könnten:\n",
    "\n",
    "1. **Feature Engineering**: Ableitung sinnvoller Kennzahlen wie Kapital-Effizienz und Umsatz pro Mitarbeiter.\n",
    "2. **Modellierung mit Decision Trees**: interpretierbares Modell, konsistent mit den Beispielen aus der Vorlesung.\n",
    "3. **Bewertung mit geeigneten Metriken**: ROC-AUC, Precision, Recall, F1-Score und Confusion Matrix mit Business-Interpretation.\n",
    "4. **Diskussion von Over/Underfitting**: über Vergleich von Train/Test-Performance und Modellkomplexität.\n",
    "\n",
    "Damit verbindet das Notebook die **theoretischen Inhalte der Vorlesung** mit einer **konkreten praktischen Umsetzung** auf einem Startup-Datensatz und ist so gestaltet, dass es gut **gelesen und nachvollzogen**, aber nicht unbedingt live präsentiert werden muss."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
